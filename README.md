# mortis

## Methods

- m1：把整个台词集全塞到 prompt 里面，让模型选择（4k 行台词大约 40k token）
- m2：分两步，第一步让模型提供适合回复的关键词，搜索后第二步让模型选择
- m3：分两步，第一步生成每一句台词的 embedding，第二步让模型输出回复，回复也生成 embedding，选择最相似的回复
